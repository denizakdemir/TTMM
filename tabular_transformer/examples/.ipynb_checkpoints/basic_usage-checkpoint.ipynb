{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTML Basic Usage Example\n",
    "\n",
    "This notebook demonstrates the basic usage of the Tabular Transformer (TTML) model using the Titanic dataset. We'll cover:\n",
    "\n",
    "1. Loading and preprocessing data\n",
    "2. Configuring and initializing the model\n",
    "3. Training the model\n",
    "4. Making predictions\n",
    "5. Basic evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Import TTML modules\n",
    "from tabular_transformer.models import TransformerEncoder\n",
    "from tabular_transformer.models.task_heads import ClassificationHead\n",
    "from tabular_transformer.training import Trainer\n",
    "from tabular_transformer.inference import predict\n",
    "\n",
    "# Import data utilities\n",
    "from data_utils import download_titanic_dataset, prepare_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data\n",
    "\n",
    "First, we'll download the Titanic dataset and prepare it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Download Titanic dataset\n",
    "df = download_titanic_dataset(save_csv=False)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFeature types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare dataset for training\n",
    "target_column = 'survived'\n",
    "data = prepare_dataset(\n",
    "    df=df,\n",
    "    target_column=target_column,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure and Initialize Model\n",
    "\n",
    "Now we'll set up the TTML model with a classification head for the survival prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model configuration\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# Initialize transformer encoder\n",
    "encoder = TransformerEncoder(\n",
    "    input_dim=input_dim,\n",
    "    d_model=64,\n",
    "    nhead=4,\n",
    "    num_layers=2,\n",
    "    dim_feedforward=128,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# Initialize classification head\n",
    "task_head = ClassificationHead(\n",
    "    input_dim=64,  # Should match d_model from encoder\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train.values)\n",
    "y_train_tensor = torch.LongTensor(y_train.values)\n",
    "X_test_tensor = torch.FloatTensor(X_test.values)\n",
    "y_test_tensor = torch.LongTensor(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model\n",
    "\n",
    "We'll use the TTML Trainer to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    encoder=encoder,\n",
    "    task_head=task_head,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=32,\n",
    "    num_epochs=10\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = trainer.fit(\n",
    "    X_train=X_train_tensor,\n",
    "    y_train=y_train_tensor,\n",
    "    X_val=X_test_tensor,\n",
    "    y_val=y_test_tensor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make Predictions\n",
    "\n",
    "Let's use our trained model to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Make predictions\n",
    "predictions = predict.predict(\n",
    "    encoder=encoder,\n",
    "    task_head=task_head,\n",
    "    X=X_test_tensor\n",
    ")\n",
    "\n",
    "# Convert predictions to numpy for evaluation\n",
    "y_pred = predictions.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Results\n",
    "\n",
    "Finally, let's evaluate our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the basic usage of the TTML model for a binary classification task using the Titanic dataset. The model achieved reasonable performance in predicting survival outcomes.\n",
    "\n",
    "For more advanced usage and different tasks, check out the other example notebooks:\n",
    "- classification_examples.ipynb\n",
    "- regression_examples.ipynb\n",
    "- clustering_examples.ipynb\n",
    "- survival_analysis.ipynb\n",
    "- multi_task_examples.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
