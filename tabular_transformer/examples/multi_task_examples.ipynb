{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTML Multi-Task Learning Examples\n",
    "\n",
    "This notebook demonstrates advanced usage of the TTML model for multi-task learning scenarios. We'll cover:\n",
    "\n",
    "1. Multi-Task Learning\n",
    "   - Combining classification and regression tasks\n",
    "   - Joint feature learning\n",
    "   - Task-specific performance analysis\n",
    "\n",
    "2. Transfer Learning\n",
    "   - Pre-training on large datasets\n",
    "   - Fine-tuning for specific tasks\n",
    "   - Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "# Import TTML modules\n",
    "from tabular_transformer.models import TabularTransformer\n",
    "from tabular_transformer.models.task_heads import (\n",
    "    ClassificationHead,\n",
    "    RegressionHead,\n",
    "    MultiTaskHead\n",
    ")\n",
    "from tabular_transformer.training import Trainer\n",
    "from tabular_transformer.inference import predict\n",
    "from tabular_transformer.explainability import global_explanations\n",
    "from tabular_transformer.utils.config import TransformerConfig\n",
    "from tabular_transformer.data.dataset import TabularDataset\n",
    "\n",
    "# Import data utilities\n",
    "from data_utils import download_adult_dataset, download_wine_quality_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Multi-Task Learning\n",
    "\n",
    "We'll use the Wine Quality dataset to simultaneously predict quality scores (regression) and wine type (classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download both red and white wine datasets\n",
    "wine_red = download_wine_quality_dataset(save_csv=False, variant='red')\n",
    "wine_white = download_wine_quality_dataset(save_csv=False, variant='white')\n",
    "\n",
    "# Add wine type indicator\n",
    "wine_red['wine_type'] = 0  # Red wine\n",
    "wine_white['wine_type'] = 1  # White wine\n",
    "\n",
    "# Combine datasets\n",
    "# Standardize column names - the datasets have inconsistent naming\n",
    "# The red wine dataset uses 'class' while white wine uses 'Class'\n",
    "if 'class' in wine_red.columns:\n",
    "    wine_red = wine_red.rename(columns={'class': 'quality'})\n",
    "elif 'Class' in wine_red.columns:\n",
    "    wine_red = wine_red.rename(columns={'Class': 'quality'})\n",
    "\n",
    "if 'class' in wine_white.columns:\n",
    "    wine_white = wine_white.rename(columns={'class': 'quality'})\n",
    "elif 'Class' in wine_white.columns:\n",
    "    wine_white = wine_white.rename(columns={'Class': 'quality'})\n",
    "\n",
    "# Print column names to verify\n",
    "print(\"Red wine columns (after standardization):\", wine_red.columns.tolist())\n",
    "print(\"White wine columns (after standardization):\", wine_white.columns.tolist())\n",
    "\n",
    "# Standardize column names - the datasets have inconsistent naming\n",
    "# The red wine dataset uses 'class' while white wine uses 'Class'\n",
    "if 'class' in wine_red.columns:\n",
    "    wine_red = wine_red.rename(columns={'class': 'quality'})\n",
    "elif 'Class' in wine_red.columns:\n",
    "    wine_red = wine_red.rename(columns={'Class': 'quality'})\n",
    "\n",
    "if 'class' in wine_white.columns:\n",
    "    wine_white = wine_white.rename(columns={'class': 'quality'})\n",
    "elif 'Class' in wine_white.columns:\n",
    "    wine_white = wine_white.rename(columns={'Class': 'quality'})\n",
    "\n",
    "# Print column names to verify\n",
    "print(\"Red wine columns (after standardization):\", wine_red.columns.tolist())\n",
    "print(\"White wine columns (after standardization):\", wine_white.columns.tolist())\n",
    "\n",
    "wine_df = pd.concat([wine_red, wine_white], axis=0).reset_index(drop=True)\n",
    "print(\"Combined dataset shape:\", wine_df.shape)\n",
    "print(\"\\nWine type distribution:\")\n",
    "print(wine_df['wine_type'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_features = wine_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = wine_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target columns from features\n",
    "quality_column = 'quality'\n",
    "type_column = 'wine_type'\n",
    "\n",
    "if quality_column in numeric_features:\n",
    "    numeric_features.remove(quality_column)\n",
    "if type_column in numeric_features:\n",
    "    numeric_features.remove(type_column)\n",
    "if quality_column in categorical_features:\n",
    "    categorical_features.remove(quality_column)\n",
    "if type_column in categorical_features:\n",
    "    categorical_features.remove(type_column)\n",
    "\n",
    "# Create train/test datasets\n",
    "train_dataset, test_dataset, _ = TabularDataset.from_dataframe(\n",
    "    dataframe=wine_df,\n",
    "    numeric_columns=numeric_features,\n",
    "    categorical_columns=categorical_features,\n",
    "    target_columns={\n",
    "        'quality': [quality_column],\n",
    "        'wine_type': [type_column]\n",
    "    },\n",
    "    validation_split=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature dimensions from preprocessor\n",
    "feature_dims = train_dataset.preprocessor.get_feature_dimensions()\n",
    "numeric_dim = feature_dims['numeric_dim']\n",
    "categorical_dims = feature_dims['categorical_dims']\n",
    "categorical_embedding_dims = feature_dims['categorical_embedding_dims']\n",
    "\n",
    "# Model configuration\n",
    "config = TransformerConfig(\n",
    "    embed_dim=128,\n",
    "    num_heads=8,\n",
    "    num_layers=4,\n",
    "    dropout=0.2,\n",
    "    variational=False\n",
    ")\n",
    "\n",
    "# Initialize transformer encoder\n",
    "encoder = TabularTransformer(\n",
    "    numeric_dim=numeric_dim,\n",
    "    categorical_dims=categorical_dims,\n",
    "    categorical_embedding_dims=categorical_embedding_dims,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Create task-specific heads\n",
    "quality_head = RegressionHead(\n",
    "    input_dim=128,  # Should match config.embed_dim\n",
    "    output_dim=1  # Single target value\n",
    ")\n",
    "\n",
    "type_head = ClassificationHead(\n",
    "    input_dim=128,  # Should match config.embed_dim\n",
    "    num_classes=2  # Binary classification for wine type\n",
    ")\n",
    "\n",
    "# Combine heads into multi-task head\n",
    "# Combine heads into multi-task head\n",
    "# Combine heads into multi-task head\n",
    "multi_task_head = MultiTaskHead(\n",
    "    name=\"multi_task\",\n",
    "    input_dim=128,  # Should match config.embed_dim\n",
    "    name=\"multi_task\",\n",
    "    input_dim=128,  # Should match config.embed_dim\n",
    "    heads={\n",
    "        'quality': quality_head,\n",
    "        'wine_type': type_head\n",
    "    },\n",
    "    task_weights={\n",
    "        'quality': 1.0,\n",
    "        'wine_type': 1.0\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = train_dataset.create_dataloader(batch_size=64, shuffle=True)\n",
    "test_loader = test_dataset.create_dataloader(batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    encoder=encoder,\n",
    "    task_head=multi_task_head,\n",
    "    optimizer=None,  # Will be created by trainer\n",
    "    device=None  # Will use CUDA if available\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    num_epochs=25,\n",
    "    early_stopping_patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = trainer.predict(test_loader)\n",
    "\n",
    "# Get predictions for each task\n",
    "quality_pred = predictions['quality']['predictions'].numpy()\n",
    "type_pred = torch.argmax(predictions['wine_type']['probabilities'], dim=1).numpy()\n",
    "\n",
    "# Get true values\n",
    "y_quality_test = test_dataset.targets['quality']\n",
    "y_type_test = test_dataset.targets['wine_type']\n",
    "\n",
    "# Evaluate quality predictions\n",
    "mse = mean_squared_error(y_quality_test, quality_pred)\n",
    "r2 = r2_score(y_quality_test, quality_pred)\n",
    "\n",
    "print(\"Quality Prediction Results:\")\n",
    "print(f\"RMSE: {np.sqrt(mse):.4f}\")\n",
    "print(f\"R\u00b2 Score: {r2:.4f}\")\n",
    "\n",
    "# Evaluate type predictions\n",
    "accuracy = accuracy_score(y_type_test, type_pred)\n",
    "print(\"\\nWine Type Classification Results:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot quality predictions\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(121)\n",
    "plt.scatter(y_quality_test, quality_pred, alpha=0.5)\n",
    "plt.plot([y_quality_test.min(), y_quality_test.max()],\n",
    "         [y_quality_test.min(), y_quality_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Quality')\n",
    "plt.ylabel('Predicted Quality')\n",
    "plt.title('Quality Predictions')\n",
    "\n",
    "# Plot type predictions confusion matrix\n",
    "plt.subplot(122)\n",
    "cm = pd.crosstab(y_type_test, type_pred, normalize='index')\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title('Wine Type Predictions')\n",
    "plt.xlabel('Predicted Type')\n",
    "plt.ylabel('True Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Transfer Learning\n",
    "\n",
    "Now we'll demonstrate transfer learning by pre-training on the Adult Income dataset and fine-tuning on a subset of the Wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Adult dataset\n",
    "adult_df = download_adult_dataset(save_csv=False)\n",
    "print(\"Adult dataset shape:\", adult_df.shape)\n",
    "print(\"\\nFeature types:\")\n",
    "print(adult_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_features_adult = adult_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features_adult = adult_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target column from features\n",
    "target_column = 'class'\n",
    "if target_column in numeric_features_adult:\n",
    "    numeric_features_adult.remove(target_column)\n",
    "if target_column in categorical_features_adult:\n",
    "    categorical_features_adult.remove(target_column)\n",
    "\n",
    "# Create train/test datasets\n",
    "train_dataset_adult, test_dataset_adult, _ = TabularDataset.from_dataframe(\n",
    "    dataframe=adult_df,\n",
    "    numeric_columns=numeric_features_adult,\n",
    "    categorical_columns=categorical_features_adult,\n",
    "    target_columns={'main': [target_column]},\n",
    "    validation_split=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature dimensions from preprocessor\n",
    "feature_dims_adult = train_dataset_adult.preprocessor.get_feature_dimensions()\n",
    "numeric_dim_adult = feature_dims_adult['numeric_dim']\n",
    "categorical_dims_adult = feature_dims_adult['categorical_dims']\n",
    "categorical_embedding_dims_adult = feature_dims_adult['categorical_embedding_dims']\n",
    "\n",
    "# Model configuration\n",
    "config = TransformerConfig(\n",
    "    embed_dim=128,\n",
    "    num_heads=8,\n",
    "    num_layers=4,\n",
    "    dropout=0.2,\n",
    "    variational=False\n",
    ")\n",
    "\n",
    "# Initialize transformer encoder for pre-training\n",
    "pretrain_encoder = TabularTransformer(\n",
    "    numeric_dim=numeric_dim_adult,\n",
    "    categorical_dims=categorical_dims_adult,\n",
    "    categorical_embedding_dims=categorical_embedding_dims_adult,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Initialize classification head for pre-training\n",
    "pretrain_head = ClassificationHead(\n",
    "    input_dim=128,  # Should match config.embed_dim\n",
    "    num_classes=2  # Binary classification for income\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader_adult = train_dataset_adult.create_dataloader(batch_size=64, shuffle=True)\n",
    "test_loader_adult = test_dataset_adult.create_dataloader(batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize trainer\n",
    "pretrain_trainer = Trainer(\n",
    "    encoder=pretrain_encoder,\n",
    "    task_head=pretrain_head,\n",
    "    optimizer=None,  # Will be created by trainer\n",
    "    device=None  # Will use CUDA if available\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "pretrain_history = pretrain_trainer.train(\n",
    "    train_loader=train_loader_adult,\n",
    "    val_loader=test_loader_adult,\n",
    "    num_epochs=20,\n",
    "    early_stopping_patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create small dataset for fine-tuning (10% of wine data)\n",
    "n_samples = len(train_dataset) // 10\n",
    "indices = np.random.choice(len(train_dataset), n_samples, replace=False)\n",
    "\n",
    "small_dataset = TabularDataset(\n",
    "    dataframe=wine_df.iloc[indices],\n",
    "    numeric_columns=numeric_features,\n",
    "    categorical_columns=categorical_features,\n",
    "    target_columns={'main': [quality_column]},\n",
    "    preprocessor=train_dataset.preprocessor  # Use same preprocessor\n",
    ")\n",
    "\n",
    "# Initialize new regression head for fine-tuning\n",
    "finetune_head = RegressionHead(\n",
    "    input_dim=128,  # Should match config.embed_dim\n",
    "    output_dim=1  # Single target value\n",
    ")\n",
    "\n",
    "# Freeze encoder layers\n",
    "for param in pretrain_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Create data loaders\n",
    "train_loader_small = small_dataset.create_dataloader(batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize trainer\n",
    "finetune_trainer = Trainer(\n",
    "    encoder=pretrain_encoder,\n",
    "    task_head=finetune_head,\n",
    "    optimizer=None,  # Will be created by trainer\n",
    "    device=None  # Will use CUDA if available\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "finetune_history = finetune_trainer.train(\n",
    "    train_loader=train_loader_small,\n",
    "    val_loader=test_loader,\n",
    "    num_epochs=10,\n",
    "    early_stopping_patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a new model from scratch on the same small dataset\n",
    "scratch_encoder = TabularTransformer(\n",
    "    numeric_dim=numeric_dim,\n",
    "    categorical_dims=categorical_dims,\n",
    "    categorical_embedding_dims=categorical_embedding_dims,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "scratch_head = RegressionHead(\n",
    "    input_dim=128,  # Should match config.embed_dim\n",
    "    output_dim=1  # Single target value\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "scratch_trainer = Trainer(\n",
    "    encoder=scratch_encoder,\n",
    "    task_head=scratch_head,\n",
    "    optimizer=None,  # Will be created by trainer\n",
    "    device=None  # Will use CUDA if available\n",
    ")\n",
    "\n",
    "# Train from scratch\n",
    "scratch_history = scratch_trainer.train(\n",
    "    train_loader=train_loader_small,\n",
    "    val_loader=test_loader,\n",
    "    num_epochs=10,\n",
    "    early_stopping_patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "transfer_predictions = finetune_trainer.predict(test_loader)\n",
    "scratch_predictions = scratch_trainer.predict(test_loader)\n",
    "\n",
    "# Get predictions\n",
    "transfer_pred = transfer_predictions['main']['predictions'].numpy()\n",
    "scratch_pred = scratch_predictions['main']['predictions'].numpy()\n",
    "\n",
    "# Get true values\n",
    "y_test = test_dataset.targets['main']\n",
    "\n",
    "# Compare results\n",
    "transfer_mse = mean_squared_error(y_test, transfer_pred)\n",
    "transfer_r2 = r2_score(y_test, transfer_pred)\n",
    "\n",
    "scratch_mse = mean_squared_error(y_test, scratch_pred)\n",
    "scratch_r2 = r2_score(y_test, scratch_pred)\n",
    "\n",
    "print(\"Transfer Learning Results:\")\n",
    "print(f\"RMSE: {np.sqrt(transfer_mse):.4f}\")\n",
    "print(f\"R\u00b2 Score: {transfer_r2:.4f}\")\n",
    "\n",
    "print(\"\\nTraining from Scratch Results:\")\n",
    "print(f\"RMSE: {np.sqrt(scratch_mse):.4f}\")\n",
    "print(f\"R\u00b2 Score: {scratch_r2:.4f}\")\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(y_test, transfer_pred, alpha=0.5, label='Transfer Learning')\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Quality')\n",
    "plt.ylabel('Predicted Quality')\n",
    "plt.title('Transfer Learning Predictions')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(y_test, scratch_pred, alpha=0.5, label='From Scratch')\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Quality')\n",
    "plt.ylabel('Predicted Quality')\n",
    "plt.title('Training from Scratch Predictions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated advanced capabilities of the TTML model:\n",
    "\n",
    "1. Multi-Task Learning\n",
    "   - Successfully combined quality regression and type classification\n",
    "   - Achieved good performance on both tasks\n",
    "   - Demonstrated shared feature learning\n",
    "\n",
    "2. Transfer Learning\n",
    "   - Effectively transferred knowledge from Adult dataset\n",
    "   - Improved performance on small Wine dataset\n",
    "   - Showed benefits over training from scratch\n",
    "\n",
    "These techniques show how the TTML model can be used effectively in scenarios with limited data or multiple related tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}