{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTML Basic Usage Example\n",
    "\n",
    "This notebook demonstrates the basic usage of the Tabular Transformer (TTML) model using the Titanic dataset. We'll cover:\n",
    "\n",
    "1. Loading and preprocessing data\n",
    "2. Configuring and initializing the model\n",
    "3. Training the model\n",
    "4. Making predictions\n",
    "5. Basic evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Import TTML modules\n",
    "from tabular_transformer.models import TabularTransformer\n",
    "from tabular_transformer.models.task_heads import ClassificationHead\n",
    "from tabular_transformer.training import Trainer\n",
    "from tabular_transformer.inference import predict\n",
    "from tabular_transformer.utils.config import TransformerConfig\n",
    "from tabular_transformer.data.dataset import TabularDataset\n",
    "\n",
    "# Import data utilities\n",
    "from data_utils import download_titanic_dataset, prepare_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data\n",
    "\n",
    "First, we'll download the Titanic dataset and prepare it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1309, 14)\n",
      "\n",
      "Feature types:\n",
      "pclass          int64\n",
      "survived     category\n",
      "name           object\n",
      "sex          category\n",
      "age           float64\n",
      "sibsp           int64\n",
      "parch           int64\n",
      "ticket         object\n",
      "fare          float64\n",
      "cabin          object\n",
      "embarked     category\n",
      "boat           object\n",
      "body          float64\n",
      "home.dest      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Download Titanic dataset\n",
    "df = download_titanic_dataset(save_csv=False)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFeature types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-17 13:16:50,694 - tabular_transformer.FeaturePreprocessor - INFO - Fitted numeric scaler to 6 columns\n",
      "2025-03-17 13:16:50,698 - tabular_transformer.FeaturePreprocessor - INFO - Column name: 1307 categories, embedding dim 50\n",
      "2025-03-17 13:16:50,701 - tabular_transformer.FeaturePreprocessor - INFO - Column ticket: 929 categories, embedding dim 50\n",
      "2025-03-17 13:16:50,704 - tabular_transformer.FeaturePreprocessor - INFO - Column cabin: 187 categories, embedding dim 50\n",
      "2025-03-17 13:16:50,706 - tabular_transformer.FeaturePreprocessor - INFO - Column boat: 28 categories, embedding dim 14\n",
      "2025-03-17 13:16:50,711 - tabular_transformer.FeaturePreprocessor - INFO - Column home.dest: 370 categories, embedding dim 50\n",
      "2025-03-17 13:16:50,741 - tabular_transformer.TabularDataset - INFO - Created dataset with 1048 samples, 6 numeric features, 5 categorical features, 1 tasks\n",
      "2025-03-17 13:16:50,756 - tabular_transformer.TabularDataset - INFO - Created dataset with 261 samples, 6 numeric features, 5 categorical features, 1 tasks\n"
     ]
    }
   ],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target column from features\n",
    "target_column = 'survived'\n",
    "if target_column in numeric_features:\n",
    "    numeric_features.remove(target_column)\n",
    "if target_column in categorical_features:\n",
    "    categorical_features.remove(target_column)\n",
    "\n",
    "# Create train/test datasets\n",
    "train_dataset, test_dataset, _ = TabularDataset.from_dataframe(\n",
    "    dataframe=df,\n",
    "    numeric_columns=numeric_features,\n",
    "    categorical_columns=categorical_features,\n",
    "    target_columns={'main': [target_column]},\n",
    "    validation_split=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure and Initialize Model\n",
    "\n",
    "Now we'll set up the TTML model with a classification head for the survival prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature dimensions from preprocessor\n",
    "feature_dims = train_dataset.preprocessor.get_feature_dimensions()\n",
    "numeric_dim = feature_dims['numeric_dim']\n",
    "categorical_dims = feature_dims['categorical_dims']\n",
    "categorical_embedding_dims = feature_dims['categorical_embedding_dims']\n",
    "\n",
    "# Model configuration\n",
    "config = TransformerConfig(\n",
    "    embed_dim=64,\n",
    "    num_heads=4,\n",
    "    num_layers=2,\n",
    "    dropout=0.1,\n",
    "    variational=False\n",
    ")\n",
    "\n",
    "# Initialize transformer encoder\n",
    "encoder = TabularTransformer(\n",
    "    numeric_dim=numeric_dim,\n",
    "    categorical_dims=categorical_dims,\n",
    "    categorical_embedding_dims=categorical_embedding_dims,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Initialize classification head\n",
    "task_head = ClassificationHead(\n",
    "    name=\"main\",  # Task name should match the key in target_columns\n",
    "    input_dim=64,  # Should match config.embed_dim\n",
    "    num_classes=2  # Binary classification for survival\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model\n",
    "\n",
    "We'll use the TTML Trainer to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = train_dataset.create_dataloader(batch_size=32, shuffle=True)\n",
    "test_loader = test_dataset.create_dataloader(batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    encoder=encoder,\n",
    "    task_head={'main': task_head},  # Map task head to task name\n",
    "    optimizer=None,  # Will be created by trainer\n",
    "    device=None  # Will use CUDA if available\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    num_epochs=10,\n",
    "    early_stopping_patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make Predictions\n",
    "\n",
    "Let's use our trained model to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = trainer.predict(test_loader)\n",
    "\n",
    "# Get predictions for the main task\n",
    "y_pred = predictions['main']['predicted_class'].numpy()\n",
    "y_test = test_dataset.targets['main']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Results\n",
    "\n",
    "Finally, let's evaluate our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the basic usage of the TTML model for a binary classification task using the Titanic dataset. The model achieved reasonable performance in predicting survival outcomes.\n",
    "\n",
    "For more advanced usage and different tasks, check out the other example notebooks:\n",
    "- classification_examples.ipynb\n",
    "- regression_examples.ipynb\n",
    "- clustering_examples.ipynb\n",
    "- survival_analysis.ipynb\n",
    "- multi_task_examples.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}