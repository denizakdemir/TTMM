{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTML Classification Examples\n",
    "\n",
    "This notebook demonstrates using the TTML model for various classification tasks. We'll cover:\n",
    "\n",
    "1. Adult Income Classification\n",
    "   - Binary classification predicting income >50K\n",
    "   - Handling mixed categorical and numerical features\n",
    "   - Feature importance analysis\n",
    "\n",
    "2. Titanic Survival Classification\n",
    "   - Advanced preprocessing techniques\n",
    "   - Model interpretation\n",
    "   - Performance visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Import TTML modules\n",
    "from tabular_transformer.models import TabularTransformer\n",
    "from tabular_transformer.models.task_heads import ClassificationHead\n",
    "from tabular_transformer.training import Trainer\n",
    "from tabular_transformer.inference import predict\n",
    "from tabular_transformer.explainability import global_explanations, local_explanations\n",
    "from tabular_transformer.utils.config import TransformerConfig\n",
    "from tabular_transformer.data.dataset import TabularDataset\n",
    "\n",
    "# Import data utilities\n",
    "from data_utils import download_adult_dataset, download_titanic_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Adult Income Classification\n",
    "\n",
    "First, we'll work with the Adult Income dataset to predict whether an individual's income exceeds $50K/year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Adult dataset\n",
    "adult_df = download_adult_dataset(save_csv=False)\n",
    "print(\"Adult dataset shape:\", adult_df.shape)\n",
    "print(\"\\nFeature types:\")\n",
    "print(adult_df.dtypes)\n",
    "print(\"\\nClass distribution:\")\n",
    "print(adult_df['class'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_features = adult_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = adult_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target column from features\n",
    "target_column = 'class'\n",
    "if target_column in numeric_features:\n",
    "    numeric_features.remove(target_column)\n",
    "if target_column in categorical_features:\n",
    "    categorical_features.remove(target_column)\n",
    "\n",
    "# Create train/test datasets\n",
    "train_dataset_adult, test_dataset_adult, _ = TabularDataset.from_dataframe(\n",
    "    dataframe=adult_df,\n",
    "    numeric_columns=numeric_features,\n",
    "    categorical_columns=categorical_features,\n",
    "    target_columns={'main': [target_column]},\n",
    "    validation_split=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature dimensions from preprocessor\n",
    "feature_dims = train_dataset_adult.preprocessor.get_feature_dimensions()\n",
    "numeric_dim = feature_dims['numeric_dim']\n",
    "categorical_dims = feature_dims['categorical_dims']\n",
    "categorical_embedding_dims = feature_dims['categorical_embedding_dims']\n",
    "\n",
    "# Model configuration\n",
    "config = TransformerConfig(\n",
    "    embed_dim=128,\n",
    "    num_heads=8,\n",
    "    num_layers=4,\n",
    "    dropout=0.2,\n",
    "    variational=False\n",
    ")\n",
    "\n",
    "# Initialize transformer encoder\n",
    "encoder_adult = TabularTransformer(\n",
    "    numeric_dim=numeric_dim,\n",
    "    categorical_dims=categorical_dims,\n",
    "    categorical_embedding_dims=categorical_embedding_dims,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Initialize classification head\n",
    "task_head_adult = ClassificationHead(\n",
    "    input_dim=128,  # Should match config.embed_dim\n",
    "    num_classes=2  # Binary classification for income\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader_adult = train_dataset_adult.create_dataloader(batch_size=64, shuffle=True)\n",
    "test_loader_adult = test_dataset_adult.create_dataloader(batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer_adult = Trainer(\n",
    "    encoder=encoder_adult,\n",
    "    task_head=task_head_adult,\n",
    "    optimizer=None,  # Will be created by trainer\n",
    "    device=None  # Will use CUDA if available\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history_adult = trainer_adult.train(\n",
    "    train_loader=train_loader_adult,\n",
    "    val_loader=test_loader_adult,\n",
    "    num_epochs=20,\n",
    "    early_stopping_patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions_adult = trainer_adult.predict(test_loader_adult)\n",
    "\n",
    "# Get predictions for the main task\n",
    "y_pred_adult = predictions_adult['main']['predictions'].numpy()\n",
    "y_test_adult = test_dataset_adult.targets['main']\n",
    "\n",
    "# Print metrics\n",
    "print(\"Adult Income Classification Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_adult, y_pred_adult):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_adult, y_pred_adult))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test_adult, y_pred_adult)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Adult Income Classification')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "Let's analyze which features are most important for income prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot feature importance\n",
    "feature_importance = global_explanations.calculate_feature_importance(\n",
    "    encoder=encoder_adult,\n",
    "    task_head=task_head_adult,\n",
    "    dataset=test_dataset_adult,\n",
    "    feature_names=numeric_features + categorical_features\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "feature_importance.sort_values().plot(kind='barh')\n",
    "plt.title('Feature Importance - Adult Income Classification')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Titanic Survival Classification\n",
    "\n",
    "Now we'll demonstrate some advanced techniques with the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Titanic dataset\n",
    "titanic_df = download_titanic_dataset(save_csv=False)\n",
    "print(\"Titanic dataset shape:\", titanic_df.shape)\n",
    "print(\"\\nFeature types:\")\n",
    "print(titanic_df.dtypes)\n",
    "print(\"\\nSurvival distribution:\")\n",
    "print(titanic_df['survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_features = titanic_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = titanic_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target column from features\n",
    "target_column = 'survived'\n",
    "if target_column in numeric_features:\n",
    "    numeric_features.remove(target_column)\n",
    "if target_column in categorical_features:\n",
    "    categorical_features.remove(target_column)\n",
    "\n",
    "# Create train/test datasets\n",
    "train_dataset_titanic, test_dataset_titanic, _ = TabularDataset.from_dataframe(\n",
    "    dataframe=titanic_df,\n",
    "    numeric_columns=numeric_features,\n",
    "    categorical_columns=categorical_features,\n",
    "    target_columns={'main': [target_column]},\n",
    "    validation_split=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature dimensions from preprocessor\n",
    "feature_dims = train_dataset_titanic.preprocessor.get_feature_dimensions()\n",
    "numeric_dim = feature_dims['numeric_dim']\n",
    "categorical_dims = feature_dims['categorical_dims']\n",
    "categorical_embedding_dims = feature_dims['categorical_embedding_dims']\n",
    "\n",
    "# Model configuration\n",
    "config = TransformerConfig(\n",
    "    embed_dim=64,\n",
    "    num_heads=4,\n",
    "    num_layers=2,\n",
    "    dropout=0.1,\n",
    "    variational=False\n",
    ")\n",
    "\n",
    "# Initialize transformer encoder\n",
    "encoder_titanic = TabularTransformer(\n",
    "    numeric_dim=numeric_dim,\n",
    "    categorical_dims=categorical_dims,\n",
    "    categorical_embedding_dims=categorical_embedding_dims,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Initialize classification head\n",
    "task_head_titanic = ClassificationHead(\n",
    "    input_dim=64,  # Should match config.embed_dim\n",
    "    num_classes=2  # Binary classification for survival\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader_titanic = train_dataset_titanic.create_dataloader(batch_size=32, shuffle=True)\n",
    "test_loader_titanic = test_dataset_titanic.create_dataloader(batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer_titanic = Trainer(\n",
    "    encoder=encoder_titanic,\n",
    "    task_head=task_head_titanic,\n",
    "    optimizer=None,  # Will be created by trainer\n",
    "    device=None  # Will use CUDA if available\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history_titanic = trainer_titanic.train(\n",
    "    train_loader=train_loader_titanic,\n",
    "    val_loader=test_loader_titanic,\n",
    "    num_epochs=15,\n",
    "    early_stopping_patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions_titanic = trainer_titanic.predict(test_loader_titanic)\n",
    "\n",
    "# Get predictions for the main task\n",
    "y_pred_titanic = predictions_titanic['main']['predictions'].numpy()\n",
    "y_test_titanic = test_dataset_titanic.targets['main']\n",
    "\n",
    "print(\"Titanic Survival Classification Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_titanic, y_pred_titanic):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_titanic, y_pred_titanic))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test_titanic, y_pred_titanic)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Titanic Survival Classification')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Explanations\n",
    "\n",
    "Let's examine individual predictions to understand the model's decision-making process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get local explanations for a few examples\n",
    "sample_indices = np.random.choice(len(test_dataset_titanic), 3, replace=False)\n",
    "for idx in sample_indices:\n",
    "    explanation = local_explanations.explain_prediction(\n",
    "        encoder=encoder_titanic,\n",
    "        task_head=task_head_titanic,\n",
    "        instance_idx=idx,\n",
    "        dataset=test_dataset_titanic,\n",
    "        feature_names=numeric_features + categorical_features\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nExample {idx+1}:\")\n",
    "    print(f\"True class: {y_test_titanic[idx]}\")\n",
    "    print(f\"Predicted class: {y_pred_titanic[idx]}\")\n",
    "    print(\"\\nFeature contributions:\")\n",
    "    for feature, contribution in explanation.items():\n",
    "        print(f\"{feature}: {contribution:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated advanced classification techniques using the TTML model on two different datasets:\n",
    "\n",
    "1. Adult Income Classification\n",
    "   - Achieved good performance on income prediction\n",
    "   - Identified key features through global importance analysis\n",
    "\n",
    "2. Titanic Survival Classification\n",
    "   - Demonstrated strong predictive performance\n",
    "   - Provided local explanations for individual predictions\n",
    "\n",
    "The TTML model showed its versatility in handling different types of classification tasks and its ability to provide interpretable results through various explanation techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
