{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTML Clustering Examples\n",
    "\n",
    "This notebook demonstrates using the TTML model for clustering tasks. We'll cover:\n",
    "\n",
    "1. Unsupervised Clustering\n",
    "   - Feature extraction with transformer encoder\n",
    "   - Clustering in latent space\n",
    "   - Cluster visualization and analysis\n",
    "\n",
    "2. Semi-supervised Learning\n",
    "   - Combining labeled and unlabeled data\n",
    "   - Cluster-based classification\n",
    "   - Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Import TTML modules\n",
    "from tabular_transformer.models import TabularTransformer\n",
    "from tabular_transformer.models.task_heads import ClusteringHead\n",
    "from tabular_transformer.training import Trainer\n",
    "from tabular_transformer.inference import predict\n",
    "from tabular_transformer.explainability import global_explanations\n",
    "from tabular_transformer.utils.config import TransformerConfig\n",
    "from tabular_transformer.data.dataset import TabularDataset\n",
    "\n",
    "# Import data utilities\n",
    "from data_utils import download_adult_dataset, download_wine_quality_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Unsupervised Clustering\n",
    "\n",
    "We'll use the Wine Quality dataset to demonstrate unsupervised clustering based on chemical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Wine Quality dataset\n",
    "wine_df = download_wine_quality_dataset(save_csv=False, variant='red')\n",
    "print(\"Wine Quality dataset shape:\", wine_df.shape)\n",
    "print(\"\\nFeature types:\")\n",
    "print(wine_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_features = wine_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = wine_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove quality column from features\n",
    "quality_column = 'quality'\n",
    "if quality_column in numeric_features:\n",
    "    numeric_features.remove(quality_column)\n",
    "if quality_column in categorical_features:\n",
    "    categorical_features.remove(quality_column)\n",
    "\n",
    "# Create dataset for unsupervised learning (no target)\n",
    "dataset_wine = TabularDataset(\n",
    "    dataframe=wine_df,\n",
    "    numeric_columns=numeric_features,\n",
    "    categorical_columns=categorical_features,\n",
    "    target_columns=None  # No target for unsupervised learning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature dimensions from preprocessor\n",
    "feature_dims = dataset_wine.preprocessor.get_feature_dimensions()\n",
    "numeric_dim = feature_dims['numeric_dim']\n",
    "categorical_dims = feature_dims['categorical_dims']\n",
    "categorical_embedding_dims = feature_dims['categorical_embedding_dims']\n",
    "\n",
    "# Model configuration\n",
    "config = TransformerConfig(\n",
    "    embed_dim=64,\n",
    "    num_heads=4,\n",
    "    num_layers=3,\n",
    "    dropout=0.1,\n",
    "    variational=False\n",
    ")\n",
    "\n",
    "# Initialize transformer encoder\n",
    "encoder = TabularTransformer(\n",
    "    numeric_dim=numeric_dim,\n",
    "    categorical_dims=categorical_dims,\n",
    "    categorical_embedding_dims=categorical_embedding_dims,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Initialize clustering head\n",
    "clustering_head = ClusteringHead(\n",
    "    input_dim=64,  # Should match config.embed_dim\n",
    "    n_clusters=4  # Number of wine quality clusters to discover\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "data_loader_wine = dataset_wine.create_dataloader(batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    encoder=encoder,\n",
    "    task_head=clustering_head,\n",
    "    optimizer=None,  # Will be created by trainer\n",
    "    device=None  # Will use CUDA if available\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = trainer.train(\n",
    "    train_loader=data_loader_wine,\n",
    "    num_epochs=20,\n",
    "    early_stopping_patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster assignments\n",
    "predictions = trainer.predict(data_loader_wine)\n",
    "cluster_probs = predictions['main']['probabilities']\n",
    "cluster_assignments = torch.argmax(cluster_probs, dim=1).numpy()\n",
    "\n",
    "# Calculate silhouette score\n",
    "features = np.concatenate([dataset_wine.numeric_features, dataset_wine.categorical_features], axis=1)\n",
    "silhouette_avg = silhouette_score(features, cluster_assignments)\n",
    "print(f\"Silhouette Score: {silhouette_avg:.4f}\")\n",
    "\n",
    "# Get latent representations\n",
    "latent_repr = predictions['latent_representations'].numpy()\n",
    "\n",
    "# Reduce dimensionality for visualization\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(latent_repr)\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=cluster_assignments, cmap='viridis')\n",
    "plt.colorbar(scatter)\n",
    "plt.title('Wine Clusters in Latent Space')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis\n",
    "\n",
    "Let's analyze the characteristics of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster assignments to original dataframe\n",
    "wine_df['Cluster'] = cluster_assignments\n",
    "\n",
    "# Calculate cluster statistics\n",
    "cluster_stats = wine_df.groupby('Cluster').agg([\n",
    "    'mean', 'std'\n",
    "]).round(2)\n",
    "\n",
    "print(\"Cluster Statistics:\")\n",
    "print(cluster_stats)\n",
    "\n",
    "# Plot feature distributions by cluster\n",
    "features = numeric_features + categorical_features\n",
    "n_features = len(features)\n",
    "n_cols = 3\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "plt.figure(figsize=(15, 4*n_rows))\n",
    "for i, feature in enumerate(features, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.boxplot(data=wine_df, x='Cluster', y=feature)\n",
    "    plt.title(f'{feature} by Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Semi-supervised Learning\n",
    "\n",
    "Now we'll demonstrate semi-supervised learning using the Adult Income dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Adult dataset\n",
    "adult_df = download_adult_dataset(save_csv=False)\n",
    "print(\"Adult dataset shape:\", adult_df.shape)\n",
    "print(\"\\nFeature types:\")\n",
    "print(adult_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_features = adult_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = adult_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target column from features\n",
    "target_column = 'class'\n",
    "if target_column in numeric_features:\n",
    "    numeric_features.remove(target_column)\n",
    "if target_column in categorical_features:\n",
    "    categorical_features.remove(target_column)\n",
    "\n",
    "# Create train/test datasets\n",
    "train_dataset_adult, test_dataset_adult, _ = TabularDataset.from_dataframe(\n",
    "    dataframe=adult_df,\n",
    "    numeric_columns=numeric_features,\n",
    "    categorical_columns=categorical_features,\n",
    "    target_columns={'main': [target_column]},\n",
    "    validation_split=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Simulate partially labeled data (50% labeled)\n",
    "n_samples = len(train_dataset_adult)\n",
    "n_labeled = n_samples // 2\n",
    "labeled_mask = np.zeros(n_samples, dtype=bool)\n",
    "labeled_mask[:n_labeled] = True\n",
    "np.random.shuffle(labeled_mask)\n",
    "\n",
    "# Create labeled and unlabeled datasets\n",
    "labeled_dataset = TabularDataset(\n",
    "    dataframe=adult_df.iloc[labeled_mask],\n",
    "    numeric_columns=numeric_features,\n",
    "    categorical_columns=categorical_features,\n",
    "    target_columns={'main': [target_column]},\n",
    "    preprocessor=train_dataset_adult.preprocessor  # Use same preprocessor\n",
    ")\n",
    "\n",
    "unlabeled_dataset = TabularDataset(\n",
    "    dataframe=adult_df.iloc[~labeled_mask],\n",
    "    numeric_columns=numeric_features,\n",
    "    categorical_columns=categorical_features,\n",
    "    target_columns=None,  # No targets for unlabeled data\n",
    "    preprocessor=train_dataset_adult.preprocessor  # Use same preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature dimensions from preprocessor\n",
    "feature_dims = train_dataset_adult.preprocessor.get_feature_dimensions()\n",
    "numeric_dim = feature_dims['numeric_dim']\n",
    "categorical_dims = feature_dims['categorical_dims']\n",
    "categorical_embedding_dims = feature_dims['categorical_embedding_dims']\n",
    "\n",
    "# Model configuration\n",
    "config = TransformerConfig(\n",
    "    embed_dim=128,\n",
    "    num_heads=8,\n",
    "    num_layers=4,\n",
    "    dropout=0.2,\n",
    "    variational=False\n",
    ")\n",
    "\n",
    "# Initialize transformer encoder\n",
    "encoder_semi = TabularTransformer(\n",
    "    numeric_dim=numeric_dim,\n",
    "    categorical_dims=categorical_dims,\n",
    "    categorical_embedding_dims=categorical_embedding_dims,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Initialize clustering head\n",
    "clustering_head_semi = ClusteringHead(\n",
    "    input_dim=128,  # Should match config.embed_dim\n",
    "    n_clusters=4,  # Number of clusters\n",
    "    semi_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "labeled_loader = labeled_dataset.create_dataloader(batch_size=64, shuffle=True)\n",
    "unlabeled_loader = unlabeled_dataset.create_dataloader(batch_size=64, shuffle=True)\n",
    "test_loader = test_dataset_adult.create_dataloader(batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer_semi = Trainer(\n",
    "    encoder=encoder_semi,\n",
    "    task_head=clustering_head_semi,\n",
    "    optimizer=None,  # Will be created by trainer\n",
    "    device=None  # Will use CUDA if available\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history_semi = trainer_semi.train(\n",
    "    train_loader=labeled_loader,\n",
    "    unlabeled_loader=unlabeled_loader,\n",
    "    val_loader=test_loader,\n",
    "    num_epochs=25,\n",
    "    early_stopping_patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = trainer_semi.predict(test_loader)\n",
    "\n",
    "# Get cluster assignments and latent representations\n",
    "cluster_probs = predictions['main']['probabilities']\n",
    "cluster_assignments = torch.argmax(cluster_probs, dim=1).numpy()\n",
    "latent_repr = predictions['latent_representations'].numpy()\n",
    "\n",
    "# Get true labels\n",
    "y_test = test_dataset_adult.targets['main']\n",
    "\n",
    "# Reduce dimensionality\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(latent_repr)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot clusters\n",
    "plt.subplot(121)\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=cluster_assignments, cmap='viridis')\n",
    "plt.colorbar(scatter)\n",
    "plt.title('Learned Clusters')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "\n",
    "# Plot true labels\n",
    "plt.subplot(122)\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_test, cmap='viridis')\n",
    "plt.colorbar(scatter)\n",
    "plt.title('True Labels')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate adjusted Rand index\n",
    "ari = adjusted_rand_score(y_test, cluster_assignments)\n",
    "print(f\"Adjusted Rand Index: {ari:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "Let's analyze which features are most important for the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot feature importance\n",
    "feature_importance = global_explanations.calculate_feature_importance(\n",
    "    encoder=encoder_semi,\n",
    "    task_head=clustering_head_semi,\n",
    "    dataset=test_dataset_adult,\n",
    "    feature_names=numeric_features + categorical_features\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "feature_importance.sort_values().plot(kind='barh')\n",
    "plt.title('Feature Importance for Clustering')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the clustering capabilities of the TTML model:\n",
    "\n",
    "1. Unsupervised Clustering\n",
    "   - Successfully identified natural clusters in the Wine Quality dataset\n",
    "   - Visualized cluster distributions and characteristics\n",
    "   - Achieved good cluster separation (silhouette score)\n",
    "\n",
    "2. Semi-supervised Learning\n",
    "   - Combined labeled and unlabeled data effectively\n",
    "   - Demonstrated good alignment with true labels (ARI score)\n",
    "   - Identified important features for clustering\n",
    "\n",
    "The TTML model showed its versatility in handling both fully unsupervised and semi-supervised learning tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
